{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa194ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups as getData\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6638bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = getData(subset='train',remove=('headers','footers','quotes'),return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03293ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256b7366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail. 7\n"
     ]
    }
   ],
   "source": [
    "print(X[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1468278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6063c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = defaultdict(int)\n",
    "for doc in X:\n",
    "    for token in re.split('\\W+',doc.lower()):\n",
    "        fr[token] +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5373b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffValue = 10\n",
    "processed_corpus = []\n",
    "for doc in X:\n",
    "    for token in re.split('\\W+',doc.lower()):\n",
    "        if fr[token]>=cutoffValue:\n",
    "\n",
    "            processed_corpus.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d1a5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords = np.array(list(fr.keys()))\n",
    "allCounts = np.array(list(fr.values()))\n",
    "vocab = allWords[allCounts>= cutoffValue]\n",
    "wordCounts = allCounts[allCounts>=cutoffValue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8838df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.75\n",
    "wordCounts = wordCounts**alpha\n",
    "probs = wordCounts/np.sum(wordCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddfbd19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords = len(vocab)\n",
    "W2I = dict(zip(vocab,np.arange(numWords)))\n",
    "I2W = dict(zip(np.arange(numWords),vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32f704af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99021920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientStep(w,cPos,cNeg,lr=0.001):\n",
    "    cPos_new = cPos - lr*(sigmoid(w.dot(cPos))-1)*w\n",
    "    w_new = w - lr*(sigmoid(w.dot(cPos)-1)*cPos)\n",
    "    cNeg_new = np.zeros(cNeg.shape)\n",
    "    for i in range(cNeg.shape[0]):\n",
    "        v = sigmoid(cNeg[i,:].dot(w))\n",
    "        w_new -= lr*v*cNeg[i,:]\n",
    "        cNeg_new[i,:] = cNeg[i,:] - lr*(sigmoid(cNeg[i,:].dot(w)))*w\n",
    "    return w_new,cPos_new,cNeg_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8831f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vecSGNS(W,C,doc,vocab,W2I,I2W,probs,winsize=2,k=4):\n",
    "    numTokens=len(doc)\n",
    "    for i in range(numTokens):\n",
    "        for j in range(i-winsize,i+winsize):\n",
    "            if j != i and j > 0 and j< numTokens:\n",
    "                wIdx = W2I[doc[i]]\n",
    "                posIdx = W2I[doc[j]]\n",
    "                w = W[wIdx,:]\n",
    "                cPos = C[posIdx,:]\n",
    "                cNeg = np.zeros((k,C.shape[1]))\n",
    "                m = 0\n",
    "                negIdx = []\n",
    "                for negC in np.random.choice(list(vocab),k,list(probs)):\n",
    "                    negIdx.append(W2I[negC])\n",
    "                    cNeg[m,:] = C[W2I[negC],:]\n",
    "                    m+=1\n",
    "                w_new,cPos_new,cNeg_new = gradientStep(w,cPos,cNeg)\n",
    "                W[wIdx,:],C[posIdx,:],C[negIdx,:] = w_new,cPos_new,cNeg_new\n",
    "    return W,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2be3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(numWords,100)\n",
    "C = np.random.rand(numWords,100)\n",
    "W,C = word2vecSGNS(W,C,processed_corpus,vocab,W2I,I2W,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6a6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
